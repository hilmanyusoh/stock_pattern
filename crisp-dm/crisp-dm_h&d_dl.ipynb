{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69842c4",
   "metadata": {},
   "source": [
    "# üìã CRISP-DM Framework for stock market chart pattern recognition using deep learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4219cc0",
   "metadata": {},
   "source": [
    "## Phase 1: Business Understanding\n",
    "\n",
    "1. Business Understanding\n",
    "‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå: ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏∏‡πâ‡∏ô/‡∏Ñ‡∏£‡∏¥‡∏õ‡πÇ‡∏ï (‡πÄ‡∏ä‡πà‡∏ô BTC) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏°‡∏ú‡∏™‡∏≤‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á:\n",
    "\n",
    "LSTM: ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏£‡∏≤‡∏Ñ‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πà‡∏≤‡∏á (Time-series)\n",
    "\n",
    "CNN: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏£‡∏≤‡∏ü Head & Shoulders (Pattern Recognition)\n",
    "\n",
    "NLP: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ï‡∏•‡∏≤‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡πà‡∏≤‡∏ß (Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af75b4",
   "metadata": {},
   "source": [
    "### Cell 1: Preparation \n",
    "‡∏£‡∏ß‡∏° Library ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "613fe8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "from cassandra.cluster import Cluster\n",
    "from transformers import pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# TensorFlow / Keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa19810",
   "metadata": {},
   "source": [
    "### 2.data understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5dd89823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢: 729 ‡πÅ‡∏ñ‡∏ß\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>12.4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.4</td>\n",
       "      <td>49432995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>12.4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.4</td>\n",
       "      <td>68819770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.3</td>\n",
       "      <td>77191342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>12.4</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.7</td>\n",
       "      <td>193937283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>57961993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  open  high   low  close     volume\n",
       "0 2023-01-17  12.4  12.4  12.2   12.4   49432995\n",
       "1 2023-01-18  12.4  12.5  12.2   12.4   68819770\n",
       "2 2023-01-19  12.3  12.4  12.2   12.3   77191342\n",
       "3 2023-01-20  12.4  12.7  12.3   12.7  193937283\n",
       "4 2023-01-23  12.6  12.6  12.4   12.5   57961993"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(symbol):\n",
    "    cluster = Cluster([CASSANDRA_HOST], port=CASSANDRA_PORT)\n",
    "    session = cluster.connect('data_stock')\n",
    "    query = \"SELECT time, open, high, low, close, volume FROM candlestick_data WHERE symbol=%s LIMIT 1000 ALLOW FILTERING\"\n",
    "    df = pd.DataFrame(list(session.execute(query, (symbol,))))\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = df.sort_values('time').reset_index(drop=True)\n",
    "    cluster.shutdown()\n",
    "    return df\n",
    "\n",
    "df_raw = get_data(SYMBOL)\n",
    "print(f\"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢: {len(df_raw)} ‡πÅ‡∏ñ‡∏ß\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c940a53",
   "metadata": {},
   "source": [
    "### Cell 3: Data Preparation & Labeling\n",
    "‡∏™‡∏£‡πâ‡∏≤‡∏á Label ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏ó‡∏£‡∏á H&S ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ Scaling (Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71b6340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: ‡∏û‡∏ö Pattern ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 3 ‡∏à‡∏∏‡∏î\n"
     ]
    }
   ],
   "source": [
    "def get_hs_labels(df, window=5):\n",
    "    prices = df['close'].values\n",
    "    labels = np.zeros(len(prices))\n",
    "    peaks = [i for i in range(window, len(prices)-window) if all(prices[i] > prices[i-j] and prices[i] > prices[i+j] for j in range(1, window+1))]\n",
    "    patterns = []\n",
    "    for i in range(len(peaks)-2):\n",
    "        ls, h, rs = peaks[i], peaks[i+1], peaks[i+2]\n",
    "        if prices[h] > prices[ls]*1.03 and prices[h] > prices[rs]*1.03 and abs(prices[ls]-prices[rs])/prices[ls] < 0.12:\n",
    "            labels[ls-5:rs+6] = 1\n",
    "            lv, rv = ls + np.argmin(prices[ls:h+1]), h + np.argmin(prices[h:rs+1])\n",
    "            patterns.append({'ls': (ls, prices[ls]), 'h': (h, prices[h]), 'rs': (rs, prices[rs]), 'neck': [(lv, prices[lv]), (rv, prices[rv])]})\n",
    "    return labels, patterns\n",
    "\n",
    "labels, patterns_found = get_hs_labels(df_raw)\n",
    "\n",
    "# Scaling ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LSTM (‡∏£‡∏≤‡∏Ñ‡∏≤)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df_raw[['high', 'low', 'close']])\n",
    "\n",
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏≤‡∏Å 0-1 ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏≤‡∏ó\n",
    "def inv(v): return scaler.inverse_transform(np.column_stack([np.zeros((len(v), 2)), v]))[:, 2]\n",
    "\n",
    "X_l, y_l = [], []\n",
    "for i in range(len(scaled_data)-SEQ_LEN):\n",
    "    X_l.append(scaled_data[i:i+SEQ_LEN])\n",
    "    y_l.append(scaled_data[i+SEQ_LEN, 2])\n",
    "\n",
    "X_l, y_l = np.array(X_l), np.array(y_l)\n",
    "split = int(len(X_l) * 0.8)\n",
    "print(f\"‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: ‡∏û‡∏ö Pattern ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(patterns_found)} ‡∏à‡∏∏‡∏î\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b4ce8",
   "metadata": {},
   "source": [
    "### Cell 4: Modeling (LSTM & CNN)\n",
    "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏ó‡∏£‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfb513a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hilmanyusoh/Desktop/stock_pattern/venv/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/hilmanyusoh/Desktop/stock_pattern/venv/lib/python3.13/site-packages/keras/src/callbacks/early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "/Users/hilmanyusoh/Desktop/stock_pattern/venv/lib/python3.13/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡πÅ‡∏•‡∏∞ CNN ‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\n"
     ]
    }
   ],
   "source": [
    "# 1. LSTM (Trend Prediction)\n",
    "model_lstm = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(SEQ_LEN, 3)),\n",
    "    LSTM(32),\n",
    "    Dense(1)\n",
    "])\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "model_lstm.fit(X_l[:split], y_l[:split], epochs=20, batch_size=32, verbose=0, callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "# 2. CNN (Pattern Recognition)\n",
    "X_c, y_c = [], []\n",
    "scaled_cnn = MinMaxScaler().fit_transform(df_raw[['close', 'volume']])\n",
    "for i in range(len(scaled_cnn)-SEQ_LEN):\n",
    "    X_c.append(scaled_cnn[i:i+SEQ_LEN])\n",
    "    y_c.append(labels[i+SEQ_LEN])\n",
    "X_c, y_c = np.array(X_c), np.array(y_c)\n",
    "\n",
    "cw = dict(enumerate(class_weight.compute_class_weight('balanced', classes=np.unique(y_c), y=y_c)))\n",
    "model_cnn = Sequential([\n",
    "    Conv1D(32, 3, activation='relu', input_shape=(SEQ_LEN, 2)),\n",
    "    MaxPooling1D(2), Flatten(), Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_cnn.fit(X_c[:split], y_c[:split], epochs=15, verbose=0, class_weight=cw)\n",
    "\n",
    "print(\"‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡πÅ‡∏•‡∏∞ CNN ‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110cae8",
   "metadata": {},
   "source": [
    "Cell 5: Sentiment Analysis & Future Forecasting\n",
    "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏≤‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d60ba40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Sentiment ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï 50 ‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "news = [f\"{SYMBOL} price high\", f\"Inflation impact on {SYMBOL}\", f\"Bullish market for {SYMBOL}\", f\"{SYMBOL} risk warning\"]\n",
    "results = sentiment_task(news)\n",
    "avg_sentiment = np.mean([res['score'] if res['label'] == 'POSITIVE' else -res['score'] for res in results])\n",
    "\n",
    "# Future Forecast 50 Days\n",
    "curr = scaled_data[-SEQ_LEN:].reshape(1, SEQ_LEN, 3)\n",
    "future_preds = []\n",
    "for _ in range(FORECAST_DAYS):\n",
    "    p = model_lstm.predict(curr, verbose=0)[0,0]\n",
    "    future_preds.append(p)\n",
    "    curr = np.append(curr[:, 1:, :], [[[p,p,p]]], axis=1)\n",
    "rescaled_future = inv(np.array(future_preds))\n",
    "\n",
    "print(f\"‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Sentiment ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï {FORECAST_DAYS} ‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43d9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cell 6: Evaluation (‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
